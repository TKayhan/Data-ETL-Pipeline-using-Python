{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc47b090",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow.keras as keras\n",
    "(xtrain, ytrain), (xtest, ytest) = keras.datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "276660ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(60000,)\n",
      "(10000, 28, 28)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)\n",
    "print(ytest.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "25f3a9d3",
   "metadata": {},
   "source": [
    "Veri ETL (Extract, Transform, Load) boru hattı oluştururken, veriyi normalize edip 4D tensörlere dönüştürmenin birkaç nedeni vardır:\n",
    "\n",
    "Modelin İşleyişine Uyum Sağlama: Çoğu derin öğrenme modeli, girdi olarak tensörler bekler. Özellikle evrişimli sinir ağları (CNN'ler) gibi bazı modeller, girdi tensörlerinin belirli bir şekil ve boyuta sahip olmasını gerektirir. Veriyi 4D tensörlere dönüştürmek, bu modellerle uyumlu hale getirir.\n",
    "\n",
    "Boyutluluğu Koruma: Görüntü verisi gibi çoklu boyutları olan veri türlerinde, her bir boyut farklı bir özellik veya bileşen temsil eder. Örneğin, bir görüntüde yükseklik, genişlik ve renk kanalları gibi farklı boyutlar bulunur. Bu nedenle, veriyi normalize edip 4D tensörlere dönüştürmek, bu çoklu boyutları korur ve modelin bu özellikleri kullanarak öğrenme yapmasına izin verir.\n",
    "\n",
    "Hız ve Verimlilik: Veriyi normalize etmek ve uygun bir tensör formatına dönüştürmek, işlemleri paralelleştirmeyi ve hızlandırmayı mümkün kılar. Özellikle büyük veri kümeleriyle çalışırken, veri işleme sürelerini azaltmak ve sistem performansını artırmak için önemlidir.\n",
    "\n",
    "Daha İyi Genelleme: Normalize edilmiş ve standartlaştırılmış veri, modelin daha iyi genelleme yapmasına yardımcı olabilir. Bu, modelin eğitim sırasında öğrendiklerini farklı veri kümelerine genelleme yeteneğini ifade eder."
   ]
  },
  {
   "cell_type": "raw",
   "id": "36b5edbe",
   "metadata": {},
   "source": [
    "Here we will normalize the pixel values to be between 0 and 1 and reshape the data into a 4D tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fc6d4e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28, 1)\n",
      "(60000,)\n",
      "(10000, 28, 28, 1)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "xtrain = xtrain.astype('float32') / 255\n",
    "xtest = xtest.astype('float32') / 255\n",
    "\n",
    "xtrain = np.reshape(xtrain, (xtrain.shape[0], 28, 28, 1))\n",
    "xtest = np.reshape(xtest, (xtest.shape[0], 28, 28, 1))\n",
    "\n",
    "print(xtrain.shape)\n",
    "print(ytrain.shape)\n",
    "print(xtest.shape)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62a723c1",
   "metadata": {},
   "source": [
    "Now let’s load the data into a database. We can use SQLite to create a database and load the data into it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "da0ceafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "\n",
    "conn = sqlite3.connect('fashion_mnist.db')\n",
    "\n",
    "conn.execute('''CREATE TABLE IF NOT EXISTS images\n",
    "             (id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "             image BLOB NOT NULL,\n",
    "             label INTEGER NOT NULL);''')\n",
    "\n",
    "for i in range(xtrain.shape[0]):\n",
    "    conn.execute('INSERT INTO images (image, label) VALUES (?, ?)',\n",
    "                [sqlite3.Binary(xtrain[i]), ytrain[i]])\n",
    "\n",
    "conn.commit()\n",
    "\n",
    "for i in range(xtest.shape[0]):\n",
    "    conn.execute('INSERT INTO images (image, label) VALUES (?, ?)',\n",
    "                [sqlite3.Binary(xtest[i]), ytest[i]])\n",
    "\n",
    "conn.commit()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "7c88a26d",
   "metadata": {},
   "source": [
    "Now, this is how you can read the data you stored on the SQLite database:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1e9ab40b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "conn = sqlite3.connect('fashion_mnist.db')\n",
    "cursor = conn.cursor()\n",
    "\n",
    "cursor.execute('SELECT * FROM images')\n",
    "rows = cursor.fetchall()\n",
    "\n",
    "import pandas as pd\n",
    "data=pd.read_sql_query('SELECT * FROM images',conn )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfe77317",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.5450 - accuracy: 0.8020\n",
      "Epoch 2/5\n",
      "938/938 [==============================] - 8s 9ms/step - loss: 0.3366 - accuracy: 0.8770\n",
      "Epoch 3/5\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.2898 - accuracy: 0.8949\n",
      "Epoch 4/5\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.2598 - accuracy: 0.9058\n",
      "Epoch 5/5\n",
      "938/938 [==============================] - 9s 9ms/step - loss: 0.2346 - accuracy: 0.9146\n",
      "313/313 [==============================] - 1s 3ms/step - loss: 0.2659 - accuracy: 0.9072\n",
      "Test accuracy: 0.9071999788284302\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Veri kümesini yükleme\n",
    "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
    "\n",
    "# Görüntüleri ve etiketleri normalize etme\n",
    "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
    "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
    "\n",
    "# Modeli oluşturma\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "\n",
    "# Modeli derleme\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Modeli eğitme\n",
    "model.fit(train_images, train_labels, epochs=5, batch_size=64)\n",
    "\n",
    "# Modeli değerlendirme\n",
    "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
    "print('Test accuracy:', test_acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b841394",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
